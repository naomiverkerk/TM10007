{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUo6sKbpaLD9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oysh7mvlaLEC"
      },
      "source": [
        "# TM10007 Group Assignment Machine Learning\n",
        "#### Sara Arman, Judith Essenburg, George Franssen, Naomi Verkerk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7fez-EXaLEI"
      },
      "source": [
        "## Google colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fG3XKbexaLEK"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/naomiverkerk/TM10007.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXtjii5YaLEM"
      },
      "source": [
        "## Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PGrE5j8OaLEN"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "\n",
        "from load_data import load_data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pniY-3hqaLEO"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QJTIWsKoaLEQ",
        "outputId": "0f12d96e-eb0f-4318-fee0-7653efd6b7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples/patients: 167\n",
            "The number of columns/features: 724\n"
          ]
        }
      ],
      "source": [
        "# Moeten hier nu wel even checken of X niet bevat in welke groep hij behoort\n",
        "data = load_data() \n",
        "data = data.replace('#DIV/0!', np.nan)\n",
        "X = data\n",
        "Y = data['label']\n",
        "\n",
        "# Dit betekent dat ik nu label eruit heb gehaald voor input zodat missing values werkt\n",
        "# En ook even andere 2 categorical variables zodat het scalen werkt\n",
        "X.pop('label')\n",
        "\n",
        "print(f'The number of samples/patients: {len(data.index)}')\n",
        "print(f'The number of columns/features: {len(data.columns)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKj92AxaLET"
      },
      "source": [
        "## Splitting in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mv37eW8iaLEV"
      },
      "outputs": [],
      "source": [
        "# the code to split, after that we inspect the data\n",
        "\n",
        "# Misschien hier nog stratify = Y gebruiken? Zag ik in voorbeeld\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.2, random_state = 4, stratify = Y)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdB0ncaxaLEW"
      },
      "source": [
        "## Checking/exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Cf-0fnasaLEX",
        "outputId": "396075dd-c09a-46af-b547-e6bac5095ba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index([], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#data.dtypes == 'object'\n",
        "# Seperate numerical variables and categorical variables\n",
        "#num_vars = data.columns[data.dtypes != 'object']\n",
        "cat_vars = data.columns[data.dtypes == 'object']\n",
        "\n",
        "#print(len(num_vars))\n",
        "#print(len(cat_vars))\n",
        "print(cat_vars)\n",
        "# to check which features have most missing values\n",
        "#missing_values = data[num_vars].isnull().sum().sort_values(ascending=False)\n",
        "\n",
        "#print(missing_values)\n",
        "#print(f'The total number of features with 1 or more missing values is {missing_values_multiple}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Features weghalen die te veel missing values hebben"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Je bepaalt de ratio --> heb de helft genomen en je dropt degene die boven threshold zitten\n",
        "acceptabele_ratio = 0.5\n",
        "train_size = len(X_train.index)\n",
        "removal_rate = round(train_size*0.5)\n",
        "\n",
        "X_train = X_train.dropna(axis=1, thresh=removal_rate)\n",
        "\n",
        "# maar dit moet je vervolgens ook nog droppen bij je X_test\n",
        "common_cols = list(set(X_train.columns).intersection(X_test.columns))\n",
        "X_test = X_test[common_cols]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputation --> Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In order to do scaling and PCA, first the missing values need to be filled in. \n",
        "# With scaling, it appeared that some values are infinite, so that is why those will be removed with a large finite number\n",
        "\n",
        "X_train_missing_median = X_train.fillna(X_train.median())\n",
        "X_train_missing_median = np.nan_to_num(X_train_missing_median)\n",
        "X_test_missing_median = X_test.fillna(X_test.median())\n",
        "X_test_missing_median = np.nan_to_num(X_test_missing_median)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1014: RuntimeWarning: overflow encountered in square\n",
            "  temp **= 2\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: overflow encountered in square\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in subtract\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:80: RuntimeWarning: overflow encountered in multiply\n",
            "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
          ]
        }
      ],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train_missing_median)\n",
        "X_train_scaled = scaler.transform(X_train_missing_median)\n",
        "X_train_scaled = np.nan_to_num(X_train_scaled)\n",
        "X_test_scaled = scaler.transform(X_test_missing_median)\n",
        "X_test_scaled = np.nan_to_num(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform a PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\nwver\\Documents\\TM jaar 1\\TM10007 Machine Learning\\TM10007\\assignment_ml_brats.ipynb Cell 20'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwver/Documents/TM%20jaar%201/TM10007%20Machine%20Learning/TM10007/assignment_ml_brats.ipynb#ch0000019?line=0'>1</a>\u001b[0m pca \u001b[39m=\u001b[39m decomposition\u001b[39m.\u001b[39mPCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nwver/Documents/TM%20jaar%201/TM10007%20Machine%20Learning/TM10007/assignment_ml_brats.ipynb#ch0000019?line=1'>2</a>\u001b[0m pca\u001b[39m.\u001b[39;49mfit(X_train_scaled)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwver/Documents/TM%20jaar%201/TM10007%20Machine%20Learning/TM10007/assignment_ml_brats.ipynb#ch0000019?line=2'>3</a>\u001b[0m X_train_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(X_train_scaled)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nwver/Documents/TM%20jaar%201/TM10007%20Machine%20Learning/TM10007/assignment_ml_brats.ipynb#ch0000019?line=3'>4</a>\u001b[0m X_test_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mtransform(X_test_scaled)\n",
            "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:382\u001b[0m, in \u001b[0;36mPCA.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=364'>365</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=365'>366</a>\u001b[0m     \u001b[39m\"\"\"Fit the model with X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=366'>367</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=367'>368</a>\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=379'>380</a>\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=380'>381</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=381'>382</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=382'>383</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
            "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:430\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=423'>424</a>\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=424'>425</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=425'>426</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=426'>427</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=427'>428</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=429'>430</a>\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=430'>431</a>\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=431'>432</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=433'>434</a>\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/decomposition/_pca.py?line=434'>435</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/base.py?line=563'>564</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/base.py?line=564'>565</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/base.py?line=565'>566</a>\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/base.py?line=566'>567</a>\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/base.py?line=567'>568</a>\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=798'>799</a>\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=799'>800</a>\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=801'>802</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=802'>803</a>\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
            "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=106'>107</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=107'>108</a>\u001b[0m         allow_nan\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=108'>109</a>\u001b[0m         \u001b[39mand\u001b[39;00m np\u001b[39m.\u001b[39misinf(X)\u001b[39m.\u001b[39many()\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=109'>110</a>\u001b[0m         \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=110'>111</a>\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(X)\u001b[39m.\u001b[39mall()\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=111'>112</a>\u001b[0m     ):\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=112'>113</a>\u001b[0m         type_err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minfinity\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m allow_nan \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mNaN, infinity\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=113'>114</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=114'>115</a>\u001b[0m             msg_err\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=115'>116</a>\u001b[0m                 type_err, msg_dtype \u001b[39mif\u001b[39;00m msg_dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39mdtype\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=116'>117</a>\u001b[0m             )\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=117'>118</a>\u001b[0m         )\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=118'>119</a>\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/nwver/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=119'>120</a>\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
            "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
          ]
        }
      ],
      "source": [
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment_ml_brats.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "99c346a2273ffdba9d13565a7efa8a03dbcb19c3f8c63eac036f68118855a3ce"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
