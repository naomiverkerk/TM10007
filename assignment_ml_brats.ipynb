{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUo6sKbpaLD9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oysh7mvlaLEC"
      },
      "source": [
        "# TM10007 Group Assignment Machine Learning\n",
        "#### Sara Arman, Judith Essenburg, George Franssen, Naomi Verkerk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7fez-EXaLEI"
      },
      "source": [
        "## Google colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fG3XKbexaLEK"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/naomiverkerk/TM10007.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXtjii5YaLEM"
      },
      "source": [
        "## Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "PGrE5j8OaLEN"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "from sklearn.utils.validation import check_array\n",
        "\n",
        "from load_data import load_data\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pniY-3hqaLEO"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "QJTIWsKoaLEQ",
        "outputId": "0f12d96e-eb0f-4318-fee0-7653efd6b7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples/patients: 167\n",
            "The number of columns/features: 722\n"
          ]
        }
      ],
      "source": [
        "# Moeten hier nu wel even checken of X niet bevat in welke groep hij behoort\n",
        "data = load_data() \n",
        "X = data\n",
        "Y = data['label']\n",
        "\n",
        "# Dit betekent dat ik nu label eruit heb gehaald voor input zodat missing values werkt\n",
        "# En ook even andere 2 categorical variables zodat het scalen werkt\n",
        "X.pop('label')\n",
        "X.pop('VOLUME_ET_OVER_ED')\n",
        "X.pop('VOLUME_NET_OVER_ED')\n",
        "\n",
        "\n",
        "\n",
        "print(f'The number of samples/patients: {len(data.index)}')\n",
        "print(f'The number of columns/features: {len(data.columns)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKj92AxaLET"
      },
      "source": [
        "## Splitting in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mv37eW8iaLEV"
      },
      "outputs": [],
      "source": [
        "# the code to split, after that we inspect the data\n",
        "\n",
        "# Misschien hier nog stratify = Y gebruiken? Zag ik in voorbeeld\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.2, random_state = 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdB0ncaxaLEW"
      },
      "source": [
        "## Checking/exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Cf-0fnasaLEX",
        "outputId": "396075dd-c09a-46af-b547-e6bac5095ba3"
      },
      "outputs": [],
      "source": [
        "data.dtypes == 'object'\n",
        "# Seperate numerical variables and categorical variables\n",
        "num_vars = data.columns[data.dtypes != 'object']\n",
        "cat_vars = data.columns[data.dtypes == 'object']\n",
        "\n",
        "#print(len(num_vars))\n",
        "#print(len(cat_vars))\n",
        "#print(cat_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "LEl3UCLuaLEZ",
        "outputId": "51a7fc7e-1635-43fd-9602-bfe40c39c4f9"
      },
      "outputs": [],
      "source": [
        "# to check which features have most missing values\n",
        "missing_values = data[num_vars].isnull().sum().sort_values(ascending=False)\n",
        "missing_values_multiple = (missing_values > 0).sum()\n",
        "\n",
        "#print(missing_values)\n",
        "#print(f'The total number of features with 1 or more missing values is {missing_values_multiple}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputation --> Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In order to do scaling and PCA, first the missing values need to be filled in. \n",
        "# With scaling, it appeared that some values are infinite, so that is why those will be removed with a large finite number\n",
        "\n",
        "\n",
        "X_train_missing_mean = X_train.fillna(X_train.mean())\n",
        "X_train_missing_mean = np.nan_to_num(X_train_missing_mean)\n",
        "X_test_missing_mean = X_test.fillna(X_test.mean())\n",
        "X_test_missing_mean = np.nan_to_num(X_test_missing_mean)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1014: RuntimeWarning: overflow encountered in square\n",
            "  temp **= 2\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: overflow encountered in square\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in subtract\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:80: RuntimeWarning: overflow encountered in multiply\n",
            "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
          ]
        }
      ],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train_missing_mean)\n",
        "X_train_scaled = scaler.transform(X_train_missing_mean)\n",
        "X_train_scaled = np.nan_to_num(X_train_scaled)\n",
        "X_test_scaled = scaler.transform(X_test_missing_mean)\n",
        "X_test_scaled = np.nan_to_num(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform a PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(type(X_train_pca))\n",
        "print(type(Y_train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'sklearn.discriminant_analysis.LinearDiscriminantAnalysis'>\n",
            "Acc:0.8270676691729323\n",
            "AUC:0.8983739837398375\n",
            "F1:0.8715083798882682\n",
            "precision:0.8041237113402062\n",
            "recall:0.9512195121951219\n",
            "<class 'sklearn.discriminant_analysis.QuadraticDiscriminantAnalysis'>\n",
            "Acc:0.8646616541353384\n",
            "AUC:0.9218077474892395\n",
            "F1:0.8965517241379309\n",
            "precision:0.8478260869565217\n",
            "recall:0.9512195121951219\n",
            "<class 'sklearn.naive_bayes.GaussianNB'>\n",
            "Acc:0.8195488721804511\n",
            "AUC:0.9084170253467241\n",
            "F1:0.8666666666666666\n",
            "precision:0.7959183673469388\n",
            "recall:0.9512195121951219\n",
            "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
            "Acc:0.8571428571428571\n",
            "AUC:0.8947871831659493\n",
            "F1:0.8875739644970414\n",
            "precision:0.8620689655172413\n",
            "recall:0.9146341463414634\n",
            "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
            "Acc:0.8721804511278195\n",
            "AUC:0.9450023912003825\n",
            "F1:0.9017341040462428\n",
            "precision:0.8571428571428571\n",
            "recall:0.9512195121951219\n"
          ]
        }
      ],
      "source": [
        "basic_classifiers = [LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis(), GaussianNB(), LogisticRegression(), KNeighborsClassifier()]\n",
        "# De SGDClassifier() erbij lukt me nog niet helemaal, dan krijg ik allemaal errors\n",
        "classifiers_fit = list()\n",
        "\n",
        "for classifier in basic_classifiers:\n",
        "    classifier.fit(X_train_pca, Y_train)\n",
        "    Y_predicted = classifier.predict(X_train_pca)\n",
        "    if hasattr(classifier,'predict_proba'):\n",
        "        Y_score = classifier.predict_proba(X_train_pca)[:,1]\n",
        "    else:\n",
        "        Y_score = Y_predicted\n",
        "   \n",
        "    # Calculate some quantifiable things for classifier\n",
        "    label = 'GBM'\n",
        "    auc=metrics.roc_auc_score(Y_train, Y_score)\n",
        "    accuracy=metrics.accuracy_score(Y_train, Y_predicted)\n",
        "    F1=metrics.f1_score(Y_train, Y_predicted, pos_label=label)\n",
        "    precision=metrics.precision_score(Y_train, Y_predicted, pos_label=label)\n",
        "    recall=metrics.recall_score(Y_train, Y_predicted, pos_label=label)\n",
        "\n",
        "\n",
        "# accuracy, AUC, f1score, precision, recall\n",
        "    print(type(classifier))\n",
        "    print('Acc:' +str(accuracy))\n",
        "    print('AUC:' +str(auc))\n",
        "    print('F1:' +str(F1))\n",
        "    print('precision:' +str(precision))\n",
        "    print('recall:' +str(recall))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment_ml_brats.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "99c346a2273ffdba9d13565a7efa8a03dbcb19c3f8c63eac036f68118855a3ce"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
