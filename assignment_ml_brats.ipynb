{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUo6sKbpaLD9"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oysh7mvlaLEC"
      },
      "source": [
        "# TM10007 Group Assignment Machine Learning\n",
        "#### Sara Arman, Judith Essenburg, George Franssen, Naomi Verkerk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7fez-EXaLEI"
      },
      "source": [
        "## Google colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fG3XKbexaLEK"
      },
      "outputs": [],
      "source": [
        "# Run this to use from colab environment\n",
        "#!pip install -q --upgrade git+https://github.com/naomiverkerk/TM10007.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXtjii5YaLEM"
      },
      "source": [
        "## Import\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "PGrE5j8OaLEN"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "\n",
        "from load_data import load_data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pniY-3hqaLEO"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "QJTIWsKoaLEQ",
        "outputId": "0f12d96e-eb0f-4318-fee0-7653efd6b7be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of samples/patients: 167\n",
            "The number of columns/features: 722\n"
          ]
        }
      ],
      "source": [
        "# Moeten hier nu wel even checken of X niet bevat in welke groep hij behoort\n",
        "data = load_data() \n",
        "X = data\n",
        "Y = data['label']\n",
        "\n",
        "# Dit betekent dat ik nu label eruit heb gehaald voor input zodat missing values werkt\n",
        "# En ook even andere 2 categorical variables zodat het scalen werkt\n",
        "X.pop('label')\n",
        "X.pop('VOLUME_ET_OVER_ED')\n",
        "X.pop('VOLUME_NET_OVER_ED')\n",
        "\n",
        "\n",
        "\n",
        "print(f'The number of samples/patients: {len(data.index)}')\n",
        "print(f'The number of columns/features: {len(data.columns)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdKj92AxaLET"
      },
      "source": [
        "## Splitting in train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "mv37eW8iaLEV"
      },
      "outputs": [],
      "source": [
        "# the code to split, after that we inspect the data\n",
        "\n",
        "# Misschien hier nog stratify = Y gebruiken? Zag ik in voorbeeld\n",
        "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.2, random_state = 4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdB0ncaxaLEW"
      },
      "source": [
        "## Checking/exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Cf-0fnasaLEX",
        "outputId": "396075dd-c09a-46af-b547-e6bac5095ba3"
      },
      "outputs": [],
      "source": [
        "data.dtypes == 'object'\n",
        "# Seperate numerical variables and categorical variables\n",
        "num_vars = data.columns[data.dtypes != 'object']\n",
        "cat_vars = data.columns[data.dtypes == 'object']\n",
        "\n",
        "#print(len(num_vars))\n",
        "#print(len(cat_vars))\n",
        "#print(cat_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "LEl3UCLuaLEZ",
        "outputId": "51a7fc7e-1635-43fd-9602-bfe40c39c4f9"
      },
      "outputs": [],
      "source": [
        "# to check which features have most missing values\n",
        "missing_values = data[num_vars].isnull().sum().sort_values(ascending=False)\n",
        "missing_values_multiple = (missing_values > 0).sum()\n",
        "\n",
        "#print(missing_values)\n",
        "#print(f'The total number of features with 1 or more missing values is {missing_values_multiple}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imputation --> Missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# In order to do scaling and PCA, first the missing values need to be filled in. \n",
        "# With scaling, it appeared that some values are infinite, so that is why those will be removed with a large finite number\n",
        "\n",
        "\n",
        "X_train_missing_mean = X_train.fillna(X_train.mean())\n",
        "X_train_missing_mean = np.nan_to_num(X_train_missing_mean)\n",
        "X_test_missing_mean = X_test.fillna(X_test.mean())\n",
        "X_test_missing_mean = np.nan_to_num(X_test_missing_mean)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1014: RuntimeWarning: overflow encountered in square\n",
            "  temp **= 2\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: overflow encountered in square\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:1020: RuntimeWarning: invalid value encountered in subtract\n",
            "  new_unnormalized_variance -= correction ** 2 / new_sample_count\n",
            "C:\\Users\\nwver\\miniconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:80: RuntimeWarning: overflow encountered in multiply\n",
            "  upper_bound = n_samples * eps * var + (n_samples * mean * eps) ** 2\n"
          ]
        }
      ],
      "source": [
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train_missing_mean)\n",
        "X_train_scaled = scaler.transform(X_train_missing_mean)\n",
        "X_train_scaled = np.nan_to_num(X_train_scaled)\n",
        "X_test_scaled = scaler.transform(X_test_missing_mean)\n",
        "X_test_scaled = np.nan_to_num(X_test_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform a PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca = decomposition.PCA(n_components=2)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment_ml_brats.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "99c346a2273ffdba9d13565a7efa8a03dbcb19c3f8c63eac036f68118855a3ce"
    },
    "kernelspec": {
      "display_name": "Python 3.9.5 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
