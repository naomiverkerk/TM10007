{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/naomiverkerk/TM10007.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "from load_data import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Classifiers and kernels\n",
    "import numpy as np\n",
    "from numpy import reshape\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\judit\\Documents\\TM1\\TM10007\\Groepsopdracht\\TM10007\\load_data.py:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  data = data.append(data2)\n"
     ]
    }
   ],
   "source": [
    "##Loading Data\n",
    "data = load_data() \n",
    "X = data\n",
    "X = X.replace(np.inf, np.nan)\n",
    "Y = data['label']\n",
    "del X['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.2, random_state = 4, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Features weghalen met teveel missing values\n",
    "acceptabele_ratio = 0.5\n",
    "train_size = len(X_train.index)\n",
    "removal_rate = round(train_size*acceptabele_ratio)\n",
    "\n",
    "X_train = X_train.dropna(axis=1, thresh=removal_rate)\n",
    "common_cols = list(set(X_train.columns).intersection(X_test.columns))\n",
    "X_test = X_test[common_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputation met median\n",
    "X_train_missing_median = X_train.fillna(X_train.median())\n",
    "X_train_missing_median = np.nan_to_num(X_train_missing_median)\n",
    "X_test_missing_median = X_test.fillna(X_test.median())\n",
    "X_test_missing_median = np.nan_to_num(X_test_missing_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(X_train_missing_median)\n",
    "X_train_scaled = scaler.transform(X_train_missing_median)\n",
    "X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "X_test_scaled = scaler.transform(X_test_missing_median)\n",
    "X_test_scaled = np.nan_to_num(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "pca = decomposition.PCA(n_components=0.99, svd_solver= 'full')\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_final = pca.transform(X_train_scaled)\n",
    "X_test_final = pca.transform(X_test_scaled)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(133, 5)\n",
      "(133, 1)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 1]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\judit\\Documents\\TM1\\TM10007\\Groepsopdracht\\TM10007\\Okedezefile.ipynb Cell 9'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(Y_train_final\u001b[39m.\u001b[39mshape)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m X, Y \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(X_train_final, Y_train_final):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=21'>22</a>\u001b[0m     \u001b[39m# Fit the grid\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=22'>23</a>\u001b[0m     grid\u001b[39m.\u001b[39;49mfit(X, Y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=25'>26</a>\u001b[0m \u001b[39m# Print best parameter after tuning\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/judit/Documents/TM1/TM10007/Groepsopdracht/TM10007/Okedezefile.ipynb#ch0000008?line=26'>27</a>\u001b[0m \u001b[39mprint\u001b[39m(grid\u001b[39m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:799\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/model_selection/_search.py?line=795'>796</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_refit_for_multimetric(scorers)\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/model_selection/_search.py?line=796'>797</a>\u001b[0m     refit_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrefit\n\u001b[1;32m--> <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/model_selection/_search.py?line=798'>799</a>\u001b[0m X, y, groups \u001b[39m=\u001b[39m indexable(X, y, groups)\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/model_selection/_search.py?line=799'>800</a>\u001b[0m fit_params \u001b[39m=\u001b[39m _check_fit_params(X, fit_params)\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/model_selection/_search.py?line=801'>802</a>\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:378\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=358'>359</a>\u001b[0m \u001b[39m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=359'>360</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=360'>361</a>\u001b[0m \u001b[39mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=373'>374</a>\u001b[0m \u001b[39m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=374'>375</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=376'>377</a>\u001b[0m result \u001b[39m=\u001b[39m [_make_indexable(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m iterables]\n\u001b[1;32m--> <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=377'>378</a>\u001b[0m check_consistent_length(\u001b[39m*\u001b[39;49mresult)\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=378'>379</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=329'>330</a>\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=330'>331</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=331'>332</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=332'>333</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=333'>334</a>\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    <a href='file:///c%3A/Users/judit/miniconda3/lib/site-packages/sklearn/utils/validation.py?line=334'>335</a>\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 1]"
     ]
    }
   ],
   "source": [
    "# Construct different SVM methods\n",
    "model= SVC()\n",
    "model.fit(X_train_final, Y_train)\n",
    "\n",
    "param_grid = {'degree': [1, 3, 5],\n",
    "              'coef0': [0.01, 0.5, 1],\n",
    "              'slack': [0.01, 0.5, 1],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001],\n",
    "              'kernel': ('linear', 'poly', 'rbf', 'sigmoid')}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "\n",
    "Y_array = np.asarray(Y_train)\n",
    "Y_train_final = Y_array.reshape((133,1))\n",
    "\n",
    "print(X_train_final.shape)\n",
    "print(Y_train_final.shape)\n",
    "\n",
    "\n",
    "for X, Y in zip(X_train_final, Y_train_final):\n",
    "    # Fit the grid\n",
    "    grid.fit(X, Y)\n",
    "\n",
    "\n",
    "# Print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predict with the trained model\n",
    "grid_predictions = grid.predict(X_test_final)\n",
    "\n",
    "# Print calssification report\n",
    "print(classification_report(Y_test, grid_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct different Random Forest methods\n",
    "n_estimators = [1, 5, 10, 25, 50, 75, 100]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(4, 80, 4)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 10]\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "bootstrap = [True, False]\n",
    "class_weight = ['balanced', 'balanced_subsample']\n",
    "\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "              'max_features': max_features,\n",
    "              'max_depth': max_depth,\n",
    "              'min_samples_split': min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf,\n",
    "              'bootstrap': bootstrap,\n",
    "              'class_weight': class_weight}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# Fit the grid\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "# Print best parameter after tuning\n",
    "print(grid.best_params_)\n",
    "\n",
    "# Print how our model looks after hyper-parameter tuning\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Predict with the trained model\n",
    "grid_predictions = grid.predict(X_test)\n",
    "\n",
    "# Print calssification report\n",
    "print(classification_report(Y_test, grid_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99c346a2273ffdba9d13565a7efa8a03dbcb19c3f8c63eac036f68118855a3ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
