{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to use from colab environment\n",
    "#!pip install -q --upgrade git+https://github.com/naomiverkerk/TM10007.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn import feature_selection \n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import decomposition\n",
    "from load_data import load_data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Loading Data\n",
    "data = load_data() \n",
    "X = data\n",
    "X = X.replace(np.inf, np.nan)\n",
    "Y = data['label']\n",
    "del X['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "## Split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X, Y, test_size = 0.2, random_state = 4, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Features weghalen met teveel missing values\n",
    "acceptabele_ratio = 0.5\n",
    "train_size = len(X_train.index)\n",
    "removal_rate = round(train_size*acceptabele_ratio)\n",
    "\n",
    "X_train = X_train.dropna(axis=1, thresh=removal_rate)\n",
    "common_cols = list(set(X_train.columns).intersection(X_test.columns))\n",
    "X_test = X_test[common_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imputation met median\n",
    "X_train_missing_median = X_train.fillna(X_train.median())\n",
    "X_train_missing_median = np.nan_to_num(X_train_missing_median)\n",
    "X_test_missing_median = X_test.fillna(X_test.median())\n",
    "X_test_missing_median = np.nan_to_num(X_test_missing_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling\n",
    "scaler = preprocessing.RobustScaler()\n",
    "scaler.fit(X_train_missing_median)\n",
    "X_train_scaled = scaler.transform(X_train_missing_median)\n",
    "X_train_scaled = np.nan_to_num(X_train_scaled)\n",
    "X_test_scaled = scaler.transform(X_test_missing_median)\n",
    "X_test_scaled = np.nan_to_num(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PCA\n",
    "pca = decomposition.PCA(n_components=0.99, svd_solver= 'full')\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_final = pca.transform(X_train_scaled)\n",
    "X_test_final = pca.transform(X_test_scaled)\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m<tokenize>:19\u001b[1;36m\u001b[0m\n\u001b[1;33m    for k in k_list:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "## KNN\n",
    "cv_5fold= model_selection.StratifiedKFold(n_splits=5)\n",
    "results= []\n",
    "best_n_neighbors = []\n",
    "k_list = list(range(1, 26, 2))\n",
    "train_scores = []\n",
    "validation_scores = []\n",
    "all_train = []\n",
    "all_validation = []\n",
    "\n",
    "for train_index, validation_index in cv_5fold.split(X_train_final, Y_train):\n",
    "    # Split the data properly\n",
    "    X_validation = X_train_final[validation_index]\n",
    "    Y_validation = Y_train[validation_index]\n",
    "\n",
    "    X_train = X_train_final[train_index]\n",
    "    Y_train = Y_train[train_index]\n",
    "\n",
    "   for k in k_list:\n",
    "        clf_knn = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "        clf_knn.fit(X_train, Y_train)\n",
    "\n",
    "        # Test the classifier on the training data and plot\n",
    "        train_proba = clf_knn.predict_proba(X_train)[:, 1]\n",
    "        validation_proba = clf_knn.predict_proba(X_validation)[:, 1]\n",
    "        \n",
    "        score_train = metrics.roc_auc_score(Y_train, train_proba)\n",
    "        score_validation = metrics.roc_auc_score(Y_validation, validation_proba)\n",
    "        \n",
    "\n",
    "        train_scores.append(score_train)\n",
    "        validation_scores.append(score_validation)\n",
    "        \n",
    "    all_train.append(train_scores)\n",
    "    all_validation.append(validation_scores)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#def KNN():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "99c346a2273ffdba9d13565a7efa8a03dbcb19c3f8c63eac036f68118855a3ce"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
